{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/FlorianWolff95/DHBW_BI_S24/blob/main/ML_Fallstudie_Obesity.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMu3pCvOTOaC"
      },
      "source": [
        "# ML Fallstudie Obesity\n",
        "Sie finden in unserem [Repo](https://github.com/AlexKressner/Business_Intelligence) unter `Daten/Obesity/` Daten zur Schätzung der Adipositaslevel von Personen aus den Ländern Mexiko, Peru und Kolumbien, im Alter zwischen 14 und 61 Jahren, mit unterschiedlichen Essgewohnheiten und körperlicher Verfassung. Die Daten wurden mit Hilfe einer Webplattform gesammelt, auf der anonyme Nutzer jede Frage eines Fragebogens beantworteten. Anschließend wurden die Informationen verarbeitet, wobei 17 Attribute und 2111 Datensätze erhalten wurden.\n",
        "\n",
        "Die mit den Essgewohnheiten verbundenen Attribute sind: Häufiger Konsum von hochkalorischen Lebensmitteln (FAVC), Häufigkeit des täglichen Gemüsekonsums (FCVC), Anzahl der Hauptmahlzeiten pro Tag (NCP), Konsum von Nahrungsmitteln zwischen den Mahlzeiten (CAEC), täglicher Wasserkonsum (CH20) und Alkoholkonsum (CALC).\n",
        "\n",
        "Die mit der körperlichen Verfassung verbundenen Attribute sind: Überwachung des Kalorienverbrauchs (SCC), Häufigkeit körperlicher Aktivitäten (FAF), Zeit, die mit Technologiegeräten verbracht wird (TUE), genutztes Verkehrsmittel (MTRANS) und die erhaltenen Variablen: Geschlecht, Alter, Größe und Gewicht.\n",
        "\n",
        "Die verschiedenen Adipositatswerte (in der Spalte `ObesityLevel`) sind:\n",
        "\n",
        "- Untergewicht\n",
        "- Normalgewicht\n",
        "- Übergewicht_I\n",
        "- Übergewicht_II\n",
        "- Adipositas_I\n",
        "- Adipositas_II\n",
        "- Adipositas_III\n",
        "\n",
        "Die Daten stammen von [Kaggle](https://www.kaggle.com/datasets/aravindpcoder/obesity-or-cvd-risk-classifyregressorcluster). Ihre Aufgabe besteht darin, ein geeignetes Modell zur Vorhersage des Adipositatlevels basierend auf den gegebenen Features zu erstellen. Beantworten Sie dafür die folgenden Fragestellungen bzw. gehen Sie wie folgt vor:\n",
        "\n",
        "1. **Vorüberlegung**: Wenn Sie das Adipositaslevel einer Person vorhersagen, handelt es sich um eine Regression oder Klassifikation?\n",
        "\n",
        "2. **Datenexploration**:\n",
        "- Wie viele Features gibt es?\n",
        "- Gibt es fehlende Werte bei den Features?\n",
        "- Wie sind die numerischen Features verteilt, d.h. berechnen Sie Kenngrößen wie den Mittelwert, Median, Quartile, etc.? Hinweis: Dafür gibt es eine Funktion!\n",
        "- Wie ist die Korrelation zwischen dem Target und den Features? Hinweis: Dafür gibt es eine Funktion!\n",
        "\n",
        "3. **Feature Engineering**:\n",
        "- Achte Sie auf die Datentypen beim Erstellen von Features!\n",
        "- Gibt es aus Ihrer Sicht weitere interessante Features, die Sie aus den Daten ableiten können?\n",
        "\n",
        "4. **Modell trainieren und bewerten**:\n",
        "- Entwickeln Sie ein Modell, mit dem Sie das Adipositaslevel einer Person basierend auf den zur Verfügung stehenden Features schätzen können.\n",
        "- Optimieren Sie die Hyperparamter Ihres Modells.\n",
        "- Können Sie Prognosegüte erhöhen, wenn Sie zwei Modelle trainieren? Ein Modell schätzt das Adipositaslevels für Männer, das andere für Frauen.\n",
        "\n",
        "5. **Prognose**: Schätzen Sie das Adipositaslevel einer beliebigen Person."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4AvEq0CdjGOZ"
      },
      "outputs": [],
      "source": [
        "#! git clone https://github.com/FlorianWolff95/DHBW_BI_S24"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import os\n",
        "\n",
        "\n",
        "WORKING_DIR = os.getcwd()\n",
        "\n",
        "if not os.path.exists(os.path.join(WORKING_DIR, \"Daten\")):\n",
        "    DATA_DIR = os.path.join(WORKING_DIR, \"DHBW_BI_S24\", \"Daten\")\n",
        "else:\n",
        "    DATA_DIR = os.path.join(WORKING_DIR, \"Daten\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv(os.path.join(DATA_DIR, \"Obesity\", \"ObesityDataSet.csv\"))\n",
        "df.columns = df.columns.str.strip().str.lower()\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "full_col_names = dict(\n",
        "    {\n",
        "        \"fcvc\": \"Frequent consumption of high caloric food\",\n",
        "        \"fcva\": \"Frequency of consumption of vegetables\",\n",
        "        \"ncp\": \"Number of main meal\",\n",
        "        \"caec\": \"Consumption of food between meals\",\n",
        "        \"ch2o\": \"Consumption of water daily\",\n",
        "        \"scc\": \"Calories consumption monitoring\",\n",
        "        \"faf\": \"Physical activity frequency\",\n",
        "        \"tue\": \"Time using technology devices\",\n",
        "        \"calc\": \"Consumption of alcohol\",\n",
        "        \"mtrans\": \"Transportation used\",\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. **Vorüberlegung:** Es handelt sich um MultiClass Klassifikation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. **Datenexploration**\n",
        "\n",
        "Es ist das Ziel anhand des Essverhaltens, Alter und Geschlecht vorherzusagen welches Adiporitaslevel `NObeyesdad` hat.\n",
        "Da `NObeyesdad` bestimmt wird über den `BMI`, welcher sich berechnet aus `height` und `weight`, können diese Spalten nicht zur Vorhersage verwendet werden."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "FEATURES = [\n",
        "    \"age\",\n",
        "    \"family_history_with_overweight\",\n",
        "    \"favc\",\n",
        "    \"ncp\",\n",
        "    \"caec\",\n",
        "    \"smoke\",\n",
        "    \"ch2o\",\n",
        "    \"scc\",\n",
        "    \"faf\",\n",
        "    \"tue\",\n",
        "    \"mtrans\",\n",
        "    \"calc\",\n",
        "]\n",
        "TARGET = \"nobeyesdad\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "col_cat = [\"gender\", \"caec\", \"calc\", \"mtrans\", \"nobeyesdad\"]\n",
        "cat_bool = [\"family_history_with_overweight\", \"favc\", \"smoke\", \"scc\"]\n",
        "cat_num = df.select_dtypes(\"float64\").columns.tolist()\n",
        "\n",
        "df[col_cat] = df[col_cat].astype(\"category\")\n",
        "\n",
        "df[cat_bool] = df[cat_bool].replace({\"no\": 0, \"yes\": 1}).astype(\"bool\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check for missing values\n",
        "df.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# distributions of col_cat\n",
        "for x in col_cat:\n",
        "    print(df[x].value_counts(normalize=True))\n",
        "    print(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(len(cat_num), 1, figsize=(15, 30), sharex=False)\n",
        "sns.set_style(\"whitegrid\")\n",
        "for i, col in enumerate(cat_num):\n",
        "    sns.violinplot(x=TARGET, y=col, data=df, ax=ax[i], hue=\"gender\", split=False)\n",
        "    if col in full_col_names.keys():\n",
        "        ax[i].set_ylabel(full_col_names[col])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "col_features_cat = df[FEATURES].select_dtypes(\"category\").columns.tolist() + cat_bool\n",
        "_, ax = plt.subplots(\n",
        "    len(col_features_cat),\n",
        "    2,\n",
        "    figsize=(15, len(col_features_cat) * 4),\n",
        "    width_ratios=[1, 4],\n",
        ")\n",
        "sns.set_theme(style=\"whitegrid\")\n",
        "for i, col in enumerate(col_features_cat):\n",
        "    sns.countplot(y=col, data=df, ax=ax[i, 0])\n",
        "    sns.countplot(x=col, data=df, ax=ax[i, 1], hue=TARGET)\n",
        "    if col in full_col_names.keys():\n",
        "        ax[i, 0].set_ylabel(full_col_names[col])\n",
        "        ax[i, 1].set_xlabel(full_col_names[col])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Modell trainieren"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import (\n",
        "    train_test_split,\n",
        "    StratifiedKFold,\n",
        "    GridSearchCV,\n",
        ")\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix,\n",
        "    accuracy_score,\n",
        "    f1_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        ")\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "import joblib\n",
        "\n",
        "\n",
        "if not os.path.exists(os.path.join(WORKING_DIR, \"models\")):\n",
        "    MODEL_DIR = os.path.join(WORKING_DIR, \"DHBW_BI_S24\", \"models\")\n",
        "else:\n",
        "    MODEL_DIR = os.path.join(WORKING_DIR, \"models\")\n",
        "\n",
        "model_name = \"xgb_model_obesity\"\n",
        "model_path = os.path.join(MODEL_DIR, model_name + \".joblib\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df[cat_num] = df[cat_num].round(0).astype(\"int\")\n",
        "\n",
        "one_hot_enc = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\n",
        "            \"cat\",\n",
        "            OneHotEncoder(),\n",
        "            df[FEATURES].select_dtypes(\"category\").columns.tolist(),\n",
        "        ),\n",
        "    ],\n",
        "    remainder=\"passthrough\",\n",
        ")\n",
        "\n",
        "label_enc = LabelEncoder()\n",
        "X = one_hot_enc.fit_transform(df[FEATURES])\n",
        "y = label_enc.fit_transform(df[TARGET])\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "param_grid = {\n",
        "    \"n_estimators\": [100, 500, 1000, 2000],\n",
        "    \"max_depth\": [3, 5, 7],\n",
        "    \"learning_rate\": [0.001, 0.01, 0.1],\n",
        "    \"subsample\": [0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
        "    \"colsample_bytree\": [0.4, 0.6, 0.8, 1.0],\n",
        "    \"gamma\": [0, 0.25, 0.5, 1.0],\n",
        "    \"min_child_weight\": [1, 5, 10, 15, 20],\n",
        "}\n",
        "\n",
        "classifier = XGBClassifier(\n",
        "    n_jobs=-1,\n",
        "    random_state=42,\n",
        "    booster=\"dart\",\n",
        "    tree_method=\"hist\",\n",
        "    verbosity=2,\n",
        "    num_parallel_tree=4,\n",
        "    objective=\"multi:softmax\",\n",
        "    eval_metric=\"mlogloss\",\n",
        "    num_class=7,\n",
        ")\n",
        "\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=classifier,\n",
        "    param_grid=param_grid,\n",
        "    scoring=\"accuracy\",\n",
        "    cv=cv,\n",
        "    verbose=2,\n",
        ")\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(grid_search.best_params_)\n",
        "\n",
        "joblib.dump(grid_search.best_estimator_, model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "xgb_model = joblib.load(model_path)\n",
        "y_pred = xgb_model.predict(X_test)\n",
        "\n",
        "y_test_inv = label_enc.inverse_transform(y_test)\n",
        "y_pred_inv = label_enc.inverse_transform(y_pred)\n",
        "\n",
        "cm = confusion_matrix(y_test_inv, y_pred_inv)\n",
        "plt.figure(figsize=(10, 10))\n",
        "sns.heatmap(\n",
        "    cm,\n",
        "    annot=True,\n",
        "    fmt=\"d\",\n",
        "    cmap=\"Blues\",\n",
        "    cbar=False,\n",
        "    xticklabels=label_enc.classes_,\n",
        "    yticklabels=label_enc.classes_,\n",
        ")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.show()\n",
        "\n",
        "print(\"-\" * 100 + \"\\n\" + f\"Accuracy: {accuracy_score(y_test_inv, y_pred_inv)}\\n\")\n",
        "print(\n",
        "    f'f1-score (combines precision and recall): {f1_score(y_test_inv, y_pred_inv, average=\"weighted\")}\\n'\n",
        ")\n",
        "print(\n",
        "    f'Precision (accuracy of positve -> high cost false positives): {precision_score(y_test_inv, y_pred_inv, average=\"weighted\")}\\n'\n",
        ")\n",
        "print(\n",
        "    f'Recall (Sensitivity to capture all positive instances -> high cost missing positives): {recall_score(y_test_inv, y_pred_inv, average=\"weighted\")}\\n'\n",
        "    + \"-\" * 100\n",
        "    + \"\\n\"\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyMKkrr/a6yTbpm0XkzD5viO",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
